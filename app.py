import streamlit as st
import time
import google.generativeai as genai

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="FinnBot AI", page_icon="üè¶")
def get_model():
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    except Exception:
        st.error("‚ùå Erro: Chave de API n√£o encontrada nos Secrets.")
        st.stop()
    modelos_para_tentar = [
        'gemini-1.5-flash',
        'gemini-1.5-flash-001',
        'gemini-1.5-flash-latest',
        'gemini-pro'
    ]

    for nome_modelo in modelos_para_tentar:
        try:
            model = genai.GenerativeModel(nome_modelo)
            # Teste r√°pido para ver se conecta (gera 1 token)
            model.generate_content("Oi")
            return model, nome_modelo
        except Exception:
            continue # Se falhar, tenta o pr√≥ximo da lista
    
    # Se chegou aqui, nenhum funcionou. Vamos listar o que existe.
    st.error("‚ö†Ô∏è Nenhum modelo padr√£o funcionou. Listando modelos dispon√≠veis para sua chave:")
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                st.code(m.name) # Mostra o nome correto na tela
    except Exception as e:
        st.error(f"Erro fatal ao listar modelos: {e}")
    st.stop()

# --- INICIALIZA√á√ÉO DE DADOS ---
if 'saldo_conta' not in st.session_state:
    st.session_state.saldo_conta = 0.0
if 'saldo_cofrinho' not in st.session_state:
    st.session_state.saldo_cofrinho = 0.0
if 'messages' not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Ol√°! Sou seu FinnBot. Como posso ajudar suas finan√ßas hoje?"}
    ]

# --- TENTA CONECTAR AO INICIAR ---
model, nome_conectado = get_model()

# --- BARRA LATERAL ---
with st.sidebar:
    st.title("üè¶ Meu Painel")
    # Pequeno indicador de qual modelo conectou (para debug)
    st.caption(f"üü¢ Conectado via: {nome_conectado}")
    
    st.metric("Saldo em Conta", f"R$ {st.session_state.saldo_conta:,.2f}")
    st.metric("No Cofrinho üê∑", f"R$ {st.session_state.saldo_cofrinho:,.2f}")
    
    st.divider()
    
    st.subheader("Depositar")
    valor_dep = st.number_input("Valor:", min_value=0.0, step=100.0, key="dep")
    if st.button("Confirmar Dep√≥sito"):
        st.session_state.saldo_conta += valor_dep
        st.success("Saldo atualizado!")
        time.sleep(0.5)
        st.rerun()

    st.divider()

    st.subheader("Cofrinho")
    valor_cofre = st.number_input("Opera√ß√£o cofrinho:", min_value=0.0, step=50.0, key="cof")
    c1, c2 = st.columns(2)
    with c1:
        if st.button("Guardar üì•"):
            if valor_cofre <= st.session_state.saldo_conta:
                st.session_state.saldo_conta -= valor_cofre
                st.session_state.saldo_cofrinho += valor_cofre
                st.rerun()
    with c2:
        if st.button("Resgatar üì§"):
            if valor_cofre <= st.session_state.saldo_cofrinho:
                st.session_state.saldo_cofrinho -= valor_cofre
                st.session_state.saldo_conta += valor_cofre
                st.rerun()

# --- CHAT ---
st.title("ü§ñ FinnBot: Seu Assistente")

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("Pergunte sobre seus investimentos..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        # L√≥gica Local (Saldo)
        if "saldo" in prompt.lower():
            resposta = f"üí∞ Conta: R$ {st.session_state.saldo_conta:,.2f} | üê∑ Cofrinho: R$ {st.session_state.saldo_cofrinho:,.2f}"
        
        # L√≥gica IA (Gemini)
        else:
            with st.spinner("Analisando..."):
                try:
                    instrucoes = (
                        f"Voc√™ √© o FinnBot. O usu√°rio tem R$ {st.session_state.saldo_conta:.2f}. "
                        "Responda de forma breve e direta."
                    )
                    
                    # Prepara hist√≥rico (convertendo assistant -> model)
                    history_gemini = []
                    for m in st.session_state.messages[-4:]:
                        role = "model" if m["role"] == "assistant" else "user"
                        history_gemini.append({"role": role, "parts": [m["content"]]})
                    
                    # Tenta chat com mem√≥ria
                    chat = model.start_chat(history=history_gemini[:-1])
                    response = chat.send_message(f"{instrucoes}\n\nPergunta: {prompt}")
                    resposta = response.text
                    
                except Exception as e:
                    # Fallback para resposta sem mem√≥ria se der erro
                    try:
                        resposta = model.generate_content(f"{instrucoes}\n\n{prompt}").text
                    except Exception as e2:
                        st.error(f"Erro final: {e2}")
                        resposta = "N√£o consegui responder agora."

        st.write(resposta)
        st.session_state.messages.append({"role": "assistant", "content": resposta})
